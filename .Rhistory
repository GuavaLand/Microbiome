#mask <- expand.grid(repeatBinaryNTimes)
#When N is 50, the mask is too large
#Generate random boolean mask of 100 x N
##############
#Implementation without checking duplicate observations
##############
#mask <- as.data.frame(matrix(sample(c(0,1),N*300, replace = TRUE), ncol = N))
##############
#Implementation checking duplicate observations (slow!)
##############
##First row of mask:
#mask <- as.data.frame(matrix(sample(c(0,1),50, replace = TRUE), ncol = 50))
#for (row in 2:100) {
#  tempNextRow <-  sample(c(0,1),50, replace = TRUE)
#  #Assume this has not appeared before
#  appeared <- FALSE
#  #Run through 1:row-1 to check if appeared. If yes, generate a new one and do again
#  while (TRUE) {
#    for (subrow in 1:(row-1)) {
#      if (all(mask[subrow,] == tempNextRow)) {
#        appeared <- TRUE
#        break
#      }
#    }
#    if (appeared == FALSE) {
#      #Break out of while loop
#      break
#    }
#    tempNextRow <-  sample(c(0,1),50, replace = TRUE)
#  }
#  mask[row,] <- tempNextRow
#}
#Loop through 2^N(or 300) to apply each row in mask to initial abundance, solve ode, and retrieve final abundance
#SSMatrix <- as.data.frame(matrix(nrow = 300, ncol = N))
#colnm <- c(1:N)
#colnames(SSMatrix) <- colnm
#for (i in 1:300) {
#  init <- init.x*mask[i,]
#  init <- as.numeric(init)
#  dat <- n.integrate(0:100, init, glv, list(alpha=alpha, c0=c0, l=l))
#  SSMatrix[i,] <- dat[nrow(dat),2:(N+1)]
#}
kk = growthFunction(10)
rc = findRateComponent(kk[['dat']],kk[['alpha']],kk[['c0']],kk[['l']])
head(rc)
plotRateComponent(rc[['term1']],rc[['term2']],rc[['term3']])
rc[['term1']]
library(ggplot2)
###############################################################
#This function receives three rate components (separate matrices) of all species (column) over time (row)
#and plot rate component over time for each species (N plots)
###############################################################
plotRateComponent <- function(term1, term2, term3){
########################################
#cus term3 dies out quickly, if want to look at only the beginning, run the following section
term1 <- term1[1:30,]
term2 <- term2[1:30,]
term3 <- term3[1:30,]
##########################################
#number of species
N = ncol(term1) - 2
#total rate
rate = term1[,1:N] + term2[,1:N] + term3[,1:N]
rate$time = term1$time
#Iterate through all species
for (n in 1:N) {
print(ggplot(term1,aes_string(x = 'time',y = paste('species',n,sep='')))+
geom_area(aes(fill = term),alpha=0.5) + geom_area(data=term2,aes(fill = term),alpha=0.5)+
geom_area(data = term3,aes(fill = term),alpha = 0.5)+
geom_line(data = rate)) #superimpose with overall growth rate
}
}
plotRateComponent(rc[['term1']],rc[['term2']],rc[['term3']])
library(ggplot2)
###############################################################
#This function receives three rate components (separate matrices) of all species (column) over time (row)
#and plot rate component over time for each species (N plots)
###############################################################
plotRateComponent <- function(term1, term2, term3){
########################################
#cus term3 dies out quickly, if want to look at only the beginning, run the following section
term1 <- term1[1:60,] #look at rate from begining to 60 second
term2 <- term2[1:60,]
term3 <- term3[1:60,]
##########################################
#number of species
N = ncol(term1) - 2
#total rate
rate = term1[,1:N] + term2[,1:N] + term3[,1:N]
rate$time = term1$time
#Iterate through all species
for (n in 1:N) {
print(ggplot(term1,aes_string(x = 'time',y = paste('species',n,sep='')))+
geom_area(aes(fill = term),alpha=0.5) + geom_area(data=term2,aes(fill = term),alpha=0.5)+
geom_area(data = term3,aes(fill = term),alpha = 0.5)+
geom_line(data = rate)) #superimpose with overall growth rate
}
}
plotRateComponent(rc[['term1']],rc[['term2']],rc[['term3']])
library(deSolve)
#Define GLV with varying coefficient
glv <- function(t, x, params){
with(as.list(params, c(x)),{
dx <- alpha*x + x*as.vector(c0%*%x)+x*t(t(x)%*%(do.call(cbind, lapply(l, FUN=function(ma) ma%*%x))))
list(dx)
})
}
#glv1 as original GLV
#c0 is beta
glv1 <- function(t, x, params){
with(as.list(params, c(x)),{
dx <- alpha*x + x*as.vector(c0%*%x)
list(dx)
})
}
#Define integration method
n.integrate <- function(time, init.x, model, params){
as.data.frame(lsoda(init.x, time, model, params))
}
#Define community size
#N <- 30
growthFunction <- function(N){
#Define species intrinsic growth rate
alpha <- runif(N)
#Define the constant in species-species interation coefficient
c0 <- matrix(runif(N*N, min = -1, max = 0),nrow = N)
#Set species self interation to -0.5
for (i in 1:N) {
for (j in 1:N) {
if (i == j) {
c0[i,j] <-  -0.5
}
}
}
#Define coefficient of linear term in species-species interation coefficient
ck <- runif(N*N, min = -1, max = 0.2)
ck <- matrix(ck, nrow = N)
l <- list()
for (i in 1:N) {
#For i-th matrix, i-th row is 0
temp <- ck
temp[i,] <- 0
#In i-th matrix, elements are 0 if k (column) == either j (row) or i (matrix order)
for (j in 1:N) {
for (k in 1:N) {
if (k==j | k == i) {
temp[j,k] <- 0
}
}
}
#Control the prevalence of thrid party effects
#for (element in 1:length(temp)) {
#  dice <- runif(1)
#  if (dice > -1) { #what percent of to assign 0
#    temp[element] <- 0
#  }
#}
l[[i]] <- temp
}
#Define initial abundance between 0.1 and 1, to 1 decimal place
init.x <- floor(runif(N, min = 1, max = 10))/10
#Solve the ode
dat <- n.integrate(0:500, init.x, glv, list(alpha=alpha, c0=c0, l=l))
dat1 <- n.integrate(0:500, init.x, glv1, list(alpha=alpha, c0=c0))
#Plot
matplot(x=dat$time, y=dat[,-1], typ='b', xlab='time', ylab='Absolute abundance', main=paste('Modified GLV-density', N,'species'))
matplot(x=dat1$time, y=dat1[,-1], typ='b', xlab='time', ylab='Absolute abundance', main=paste('Original GLV-density', N,'species'))
returnList <- list(dat = dat,dat1 = dat1, alpha = alpha, c0 = c0, l = l)
return(returnList)
}
###############################################################################
#Generate 2^N communities where species in each community (max possible N) are present or absent
###############################################################################
#Generate boolean mask of 2^N x N matrix
#repeatBinaryNTimes <- rep(list(c(0,1)),N)
#mask <- expand.grid(repeatBinaryNTimes)
#When N is 50, the mask is too large
#Generate random boolean mask of 100 x N
##############
#Implementation without checking duplicate observations
##############
#mask <- as.data.frame(matrix(sample(c(0,1),N*300, replace = TRUE), ncol = N))
##############
#Implementation checking duplicate observations (slow!)
##############
##First row of mask:
#mask <- as.data.frame(matrix(sample(c(0,1),50, replace = TRUE), ncol = 50))
#for (row in 2:100) {
#  tempNextRow <-  sample(c(0,1),50, replace = TRUE)
#  #Assume this has not appeared before
#  appeared <- FALSE
#  #Run through 1:row-1 to check if appeared. If yes, generate a new one and do again
#  while (TRUE) {
#    for (subrow in 1:(row-1)) {
#      if (all(mask[subrow,] == tempNextRow)) {
#        appeared <- TRUE
#        break
#      }
#    }
#    if (appeared == FALSE) {
#      #Break out of while loop
#      break
#    }
#    tempNextRow <-  sample(c(0,1),50, replace = TRUE)
#  }
#  mask[row,] <- tempNextRow
#}
#Loop through 2^N(or 300) to apply each row in mask to initial abundance, solve ode, and retrieve final abundance
#SSMatrix <- as.data.frame(matrix(nrow = 300, ncol = N))
#colnm <- c(1:N)
#colnames(SSMatrix) <- colnm
#for (i in 1:300) {
#  init <- init.x*mask[i,]
#  init <- as.numeric(init)
#  dat <- n.integrate(0:100, init, glv, list(alpha=alpha, c0=c0, l=l))
#  SSMatrix[i,] <- dat[nrow(dat),2:(N+1)]
#}
which(is.na(train_y),arr.ind = TRUE)
library(plyr)
library(randomForest)
source('ML_GetCommunityParam.R')
source('ML_CommunitySimulation.R')
source('ML_FindSSDensity.R')
source('ML_PredictionAccuracy.R')
source('ML_GetBinaryInitialState.R')
#Number of of species
N = 10
##############################
#1. Get simulation parameters: alpha, c0, l, init
#Apply binary mask to init and loop:
#2. Simulation
#3. Find Steady State Density
#1. Get simulation parameters
simulationParam <- getCommunityParam(N)
alpha <- simulationParam$alpha
c0 <- simulationParam$c0
l <- simulationParam$l
init <- simulationParam$init
#mask as presence/absence of each species
mask <- getBinaryInitialState(N, 800)
mask1 = mask$mask1 #for training
mask2 = mask$mask2 #for testing
init_mask = t(t(mask1) * init)
init_mask_2 = t(t(mask2) * init)
#2. Do simulation and save result to dat_list
dat_list <- apply(init_mask, 1, function(x){growthFunction(N,alpha,c0,l,x)})
#3. Find steady state
matrixToSS <- function(densityMatrix){
s <- apply(densityMatrix[,2:(N+1)], MARGIN = 2, findSSDensity)
return(s)
}
#output list: each member is SS density of every species
SS <- lapply(dat_list, matrixToSS)
#rbind all members in the list to form matrix
SS <- do.call(rbind, SS)
#If SS density is too small, set to 0
SS[which(SS < 0.001)] = 0
head(init_mask)
head(SS)
train_x = as.data.frame(init_mask)
train_y = as.data.frame(SS)
if (any(is.na(train_y))) {
#Row index where the row contains NA
NA_containing_rows = unique(which(is.na(train_y),arr.ind = TRUE)[,1])
#Remove NA containing rows
train_x = train_x[-NA_containing_rows,]
train_y = train_y[-NA_containing_rows,]
}
nrow(train_x)
nrow(train_y)
#for species i, if train_x starts with 0, train_y will be 0
#exclude 0
void_init = which(train_x[,i] == 0)
#Train ONE rf of each column in train_y ~ train_x
rf_species = list()
for (i in 1:N) {
#for species i, if train_x starts with 0, train_y will be 0
#exclude 0
void_init = which(train_x[,i] == 0)
train_x_filtered = train_x[-void_init,]
train_y_filtered = train_y[-void_init,]
data = cbind(train_x_filtered,y = train_y_filtered[,i])
rf_species[[i]] = randomForest(y ~ ., data = data)
}
nrow(train_x_filtered)
nrow(train_y_filtered)
test_sample_size = 50
#1. take test sample
actual_sample  = init_mask_2[50:(49 +test_sample_size),]
#2. get real final state
actual_dat_list = apply(actual_sample, 1, function(x){growthFunction(N,alpha,c0,l,x)})
#output list: each member is SS density of every species
actual_SS <- lapply(actual_dat_list, matrixToSS)
#rbind all members in the list to form matrix
actual_SS <- do.call(rbind, actual_SS)
#If SS density is too small, set to 0
actual_SS[which(actual_SS < 0.001)] = 0
nrow()actual_SS
nrow(actual_SS)
head(actual_SS)
which(is.na(actual_SS))
unique(which(is.na(actual_SS),arr.ind = TRUE)[,1])
actual_SS[35:40,]
test_sample_size = 50
#1. take test sample
actual_sample  = init_mask_2[50:(49 +test_sample_size),]
#2. get real final state
actual_dat_list = apply(actual_sample, 1, function(x){growthFunction(N,alpha,c0,l,x)})
#output list: each member is SS density of every species
actual_SS <- lapply(actual_dat_list, matrixToSS)
#rbind all members in the list to form matrix
actual_SS <- do.call(rbind, actual_SS)
#If SS density is too small, set to 0
actual_SS[which(actual_SS < 0.001)] = 0
#2.1 If we see NA in actual_SS, remove the row and remove corresponding row in actual_sample (initial state)
##Because of the assumption that the model is only used to predict community that will reach SS
if (any(is.na(actual_SS))) {
#Row index where the row contains NA
NA_containing_rows = unique(which(is.na(actual_SS),arr.ind = TRUE)[,1])
#Remove NA containing rows
actual_sample = actual_sample[-NA_containing_rows,]
actual = actual_SS[-NA_containing_rows,]
}
nrow(actual_SS)
nrow(actual_sample)
#2.1 If we see NA in actual_SS, remove the row and remove corresponding row in actual_sample (initial state)
##Because of the assumption that the model is only used to predict community that will reach SS
if (any(is.na(actual_SS))) {
#Row index where the row contains NA
NA_containing_rows = unique(which(is.na(actual_SS),arr.ind = TRUE)[,1])
#Remove NA containing rows
actual_sample = actual_sample[-NA_containing_rows,]
actual_SS = actual_SS[-NA_containing_rows,]
}
nrow(actual_sample)
nrow(actual_SS)
#output list: each member is SS density of every species
actual_SS <- lapply(actual_dat_list, matrixToSS)
#rbind all members in the list to form matrix
actual_SS <- do.call(rbind, actual_SS)
#If SS density is too small, set to 0
actual_SS[which(actual_SS < 0.001)] = 0
nrow(actual_SS)
any(is.na(actual_SS))
#1. take test sample
actual_sample  = init_mask_2[50:(49 +test_sample_size),]
nrow(actual_sample)
if (any(is.na(actual_SS))) {
#Row index where the row contains NA
NA_containing_rows = unique(which(is.na(actual_SS),arr.ind = TRUE)[,1])
#Remove NA containing rows
actual_sample = actual_sample[-NA_containing_rows,]
actual_SS = actual_SS[-NA_containing_rows,]
}
nrow(actual_sample)
nrow(actual_SS)
row = 1
data_point = t(as.data.frame(actual_sample[row,]))
head(actual_sample)
data_point
modID = 1
actual_sample[1,modID]
actual_sample[1,6]
#3. use rf_species to predict final state
predicted_SS = matrix(nrow = test_sample_size, ncol = N)
for (row in 1:nrow(actual_sample)) {
data_point = t(as.data.frame(actual_sample[row,]))
for (modID in 1:length(rf_species)) {
#3.1 if a species init density is 0, predict its final density to be 0
if (actual_sample[1,modID] == 0) {
predicted_SS[row,modID] = 0
}
else{
predicted_SS[row,modID] = predict(rf_species[[modID]],data_point)
}
}
}
head(predicted_SS)
head(actual_SS)
head(actual_sample)
predicted_SS = matrix(nrow = test_sample_size, ncol = N)
for (row in 1:nrow(actual_sample)) {
data_point = t(as.data.frame(actual_sample[row,]))
for (modID in 1:length(rf_species)) {
#3.1 if a species init density is 0, predict its final density to be 0
if (actual_sample[row,modID] == 0) {
predicted_SS[row,modID] = 0
}
else{
predicted_SS[row,modID] = predict(rf_species[[modID]],data_point)
}
}
}
head(actual_sample)
head(predicted_SS)
any(is.na(predicted_SS))
any(is.na(actual_SS))
predicted_SS
predicted_SS = matrix(nrow = nrow(actual_sample), ncol = N)
for (row in 1:nrow(actual_sample)) {
data_point = t(as.data.frame(actual_sample[row,]))
for (modID in 1:length(rf_species)) {
#3.1 if a species init density is 0, predict its final density to be 0
if (actual_sample[row,modID] == 0) {
predicted_SS[row,modID] = 0
}
else{
predicted_SS[row,modID] = predict(rf_species[[modID]],data_point)
}
}
}
is.na(actual_SS)
any(is.na(actual_SS))
any(is.na(predicted_SS))
#4. calculate accuracy
difference_score = sum(predicted_SS - actual_SS)^2
difference_score
#4. calculate accuracy
difference_score = sum(predicted_SS - actual_SS)^2/nrow(actual_SS)
difference_score
nrow(train_x_filtered)
void_init = which(train_x[,1] == 0)
train_x_filtered = train_x[-void_init,]
nrow(train_x_filtered)
a = head(predicted_SS)
b = head(actual_SS)
a-b
colSums((a-b)^2)
0.003109^2
0.08596426^2 + 0.03441766^2
#4. calculate accuracy
difference_score = colSums((predicted_SS - actual_SS)^2)/nrow(actual_SS)
difference_score
t(difference_score)
t(as.matrix(difference_score))
train_sample_size
kk = cbind(difference_score,difference_score)
kk
#Train ONE rf of each column in train_y ~ train_x, store models in rf_species
rf_species = list()
#Track how many samples used to train a model
train_sample_size = as.data.frame(matrix(nrow = N, ncol = 1))
for (i in 1:N) {
#for species i, if train_x starts with 0, train_y will be 0
#exclude 0
void_init = which(train_x[,i] == 0)
train_x_filtered = train_x[-void_init,]
train_y_filtered = train_y[-void_init,]
train_sample_size[i,1] = nrow(train_x_filtered)
data = cbind(train_x_filtered,y = train_y_filtered[,i])
rf_species[[i]] = randomForest(y ~ ., data = data)
}
test_sample_size = 50
#1. take test sample
actual_sample  = init_mask_2[50:(49 +test_sample_size),]
#2. get real final state
actual_dat_list = apply(actual_sample, 1, function(x){growthFunction(N,alpha,c0,l,x)})
#output list: each member is SS density of every species
actual_SS <- lapply(actual_dat_list, matrixToSS)
#rbind all members in the list to form matrix
actual_SS <- do.call(rbind, actual_SS)
#If SS density is too small, set to 0
actual_SS[which(actual_SS < 0.001)] = 0
#2.1 If we see NA in actual_SS, remove the row and remove corresponding row in actual_sample (initial state)
##Because of the assumption that the model is only used to predict community that will reach SS
if (any(is.na(actual_SS))) {
#Row index where the row contains NA
NA_containing_rows = unique(which(is.na(actual_SS),arr.ind = TRUE)[,1])
#Remove NA containing rows
actual_sample = actual_sample[-NA_containing_rows,]
actual_SS = actual_SS[-NA_containing_rows,]
}
#3. use rf_species to predict final state
predicted_SS = matrix(nrow = nrow(actual_sample), ncol = N)
for (row in 1:nrow(actual_sample)) {
data_point = t(as.data.frame(actual_sample[row,]))
for (modID in 1:length(rf_species)) {
#3.1 if a species init density is 0, predict its final density to be 0
if (actual_sample[row,modID] == 0) {
predicted_SS[row,modID] = 0
}
else{
predicted_SS[row,modID] = predict(rf_species[[modID]],data_point)
}
}
}
#4. calculate accuracy
difference_score = colSums((predicted_SS - actual_SS)^2)/nrow(actual_SS)
kk = cbind(train_sample_size,difference_score)
kk
getwd()
write.table(train_sample_size_difference, getwd(), sep="\t")
train_sample_size_difference = cbind(train_sample_size,difference_score)
train_sample_size_difference
write.table(train_sample_size_difference, getwd(), sep="\t")
getwd() + 'kk.csv'
getwd()
paste(getwd(),'/score',N)
paste(getwd(),'/score',N, sep = '')
write.table(train_sample_size_difference, paste(getwd(),'/score',N, sep = ''), sep="\t")
write.table(train_sample_size_difference, paste(getwd(),'/score.csv',N, sep = ''), sep="\t")
write.table(train_sample_size_difference, paste(getwd(),'/score',N,'.csv' sep = ''), sep="\t")
write.table(train_sample_size_difference, paste(getwd(),'/score',N,'.csv', sep = ''), sep="\t")
write.table(train_sample_size_difference, paste(getwd(),'/score',N,'.csv', sep = ''), sep=";")
kk
kk = 0
kk = read.csv('C:\Source\Microbiome\score10.csv',sep = '\t')
kk = read.csv('C:\\Source\\Microbiome\\score10.csv',sep = '\t')
kk
write.table(train_sample_size_difference, paste(getwd(),'/score',N,'.csv', sep = ''), sep="\t")
kk = read.csv('C:\\Source\\Microbiome\\score10.csv',sep = '\t')
kk
